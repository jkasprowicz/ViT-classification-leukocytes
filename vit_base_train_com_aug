import pandas as pd
import os
import json
from PIL import Image
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
from torchvision import transforms
import timm
from tqdm import tqdm
import matplotlib.pyplot as plt
import torchmetrics

# ----------------- Definir os caminhos do seu dataset -----------------
BASE_DIR = '/lapix/datasetvit/'
TRAIN_DIR = os.path.join(BASE_DIR, 'train')
VALID_DIR = os.path.join(BASE_DIR, 'valid')

TRAIN_CSV = os.path.join(TRAIN_DIR, '_classes.csv')
VALID_CSV = os.path.join(VALID_DIR, '_classes.csv')

#/lapix/HistAuGAN/augmented_vit/

# --- Carregar os nomes das classes (corrigido para multi-r√≥tulo) ---
try:
    df_info = pd.read_csv(TRAIN_CSV)
    # Pega o nome de todas as colunas, exceto a primeira ('filename')
    class_names = df_info.columns.tolist()[1:]
    print(f"‚úÖ Encontradas {len(class_names)} classes: {class_names}")
except FileNotFoundError:
    print(f"‚ùå Erro: Arquivo '{TRAIN_CSV}' n√£o encontrado.")
    exit()

# ----------------- Classe do Dataset (CORRIGIDA para Multi-R√≥tulo) -----------------
class LeukocyteDataset(Dataset):
    def __init__(self, csv_file, root_dir, transform=None):
        self.annotations = pd.read_csv(csv_file)
        self.root_dir = root_dir
        self.transform = transform
        print(f"Dataset carregado de '{csv_file}'. Encontradas {len(self.annotations)} imagens.")

    def __len__(self):
        return len(self.annotations)

    def __getitem__(self, idx):
        img_name = os.path.join(self.root_dir, self.annotations.iloc[idx, 0])
        image = Image.open(img_name).convert('RGB')

        # Carrega a linha inteira de 0s e 1s como o r√≥tulo
        labels = self.annotations.iloc[idx, 1:].values.astype(float)
        labels = torch.tensor(labels, dtype=torch.float32)

        if self.transform:
            image = self.transform(image)
        return image, labels

# ----------------- Hiperpar√¢metros -----------------
BATCH_SIZE = 16
NUM_EPOCHS = 50
LR = 1e-5
patience = 7 # Sua paci√™ncia original

# ----------------- Transforma√ß√µes das Imagens -----------------
# O modelo 'vit_small_patch16_384' tamb√©m espera imagens 384x384
train_transform = transforms.Compose([
    transforms.Resize((384, 384)),
    transforms.RandomHorizontalFlip(p=0.5),
    transforms.RandomVerticalFlip(p=0.5),
    transforms.RandomRotation(degrees=45),
    transforms.ColorJitter(brightness=0.3, contrast=0.3, saturation=0.3, hue=0.2),
    transforms.ToTensor(),
    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]) # Normas do ImageNet s√£o melhores
])

val_transform = transforms.Compose([
    transforms.Resize((384, 384)),
    transforms.ToTensor(),
    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
])

# ----------------- Datasets e DataLoaders -----------------
train_dataset = LeukocyteDataset(csv_file=TRAIN_CSV, root_dir=TRAIN_DIR, transform=train_transform)
val_dataset = LeukocyteDataset(csv_file=VALID_CSV, root_dir=VALID_DIR, transform=val_transform)

# REMOVIDO: WeightedRandomSampler n√£o √© ideal para multi-r√≥tulo. Usamos shuffle=True.
train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2, pin_memory=True)
val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2, pin_memory=True)

# ----------------- Dispositivo -----------------
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
print(f"üöÄ Usando dispositivo: {device}")

# ----------------- Modelo (ViT Small) -----------------
model = timm.create_model(
    'vit_base_patch16_384',  # <-- MUDAN√áA AQUI para o modelo "small"
    pretrained=True,
    num_classes=len(class_names),
    drop_rate=0.3  # Taxa de dropout para regulariza√ß√£o
)
model.to(device)

# MUDAN√áA: Fun√ß√£o de perda para multi-r√≥tulo
criterion = nn.BCEWithLogitsLoss()

# MUDAN√áA: Otimizador AdamW
optimizer = optim.AdamW(model.parameters(), lr=LR, weight_decay=1e-2)

# MUDAN√áA: Usando um scheduler mais din√¢mico
scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', factor=0.1, patience=3)

# ----------------- M√©tricas (CORRIGIDO para Multi-R√≥tulo) -----------------
history = {'epoch': [], 'train_loss': [], 'val_loss': [], 'val_acc': [], 'val_precision': [], 'val_recall': [], 'val_f1': []}
num_labels = len(class_names)
# MUDAN√áA: task="multilabel"
val_accuracy = torchmetrics.classification.Accuracy(task="multilabel", num_labels=num_labels).to(device)
val_precision = torchmetrics.classification.Precision(task="multilabel", num_labels=num_labels).to(device)
val_recall = torchmetrics.classification.Recall(task="multilabel", num_labels=num_labels).to(device)
val_f1 = torchmetrics.classification.F1Score(task="multilabel", num_labels=num_labels).to(device)

# ----------------- Loop de Treinamento (CORRIGIDO para Multi-R√≥tulo) -----------------
best_val_loss = float('inf')
epochs_no_improve = 0

for epoch in range(NUM_EPOCHS):
    model.train()
    total_train_loss = 0
    for images, labels in tqdm(train_loader, desc=f"√âpoca {epoch+1}/{NUM_EPOCHS} [Treino]"):
        images, labels = images.to(device), labels.to(device)
        optimizer.zero_grad()
        outputs = model(images)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()
        total_train_loss += loss.item()
    avg_train_loss = total_train_loss / len(train_loader)

    model.eval()
    total_val_loss = 0
    val_accuracy.reset(); val_precision.reset(); val_recall.reset(); val_f1.reset()
    with torch.no_grad():
        for images, labels in tqdm(val_loader, desc=f"√âpoca {epoch+1}/{NUM_EPOCHS} [Valida√ß√£o]"):
            images, labels = images.to(device), labels.to(device)
            outputs = model(images)
            loss = criterion(outputs, labels)
            total_val_loss += loss.item()

            # MUDAN√áA: Usar sigmoid para obter predi√ß√µes em multi-r√≥tulo
            preds = torch.sigmoid(outputs)
            val_accuracy.update(preds, labels.int())
            val_precision.update(preds, labels.int())
            val_recall.update(preds, labels.int())
            val_f1.update(preds, labels.int())

    avg_val_loss = total_val_loss / len(val_loader)
    acc = val_accuracy.compute(); prec = val_precision.compute(); rec = val_recall.compute(); f1 = val_f1.compute()

    print(f"\n‚úÖ √âpoca [{epoch+1}/{NUM_EPOCHS}] | Loss Treino: {avg_train_loss:.4f} | Loss Valida√ß√£o: {avg_val_loss:.4f}\n"
          f"Acur√°cia: {acc:.4f} | Precis√£o: {prec:.4f} | Recall: {rec:.4f} | F1-Score: {f1:.4f}\n")

    history['epoch'].append(epoch + 1); history['train_loss'].append(avg_train_loss); history['val_loss'].append(avg_val_loss)
    history['val_acc'].append(acc.item()); history['val_precision'].append(prec.item()); history['val_recall'].append(rec.item())
    history['val_f1'].append(f1.item())

    # MUDAN√áA: scheduler.step(avg_val_loss) para ReduceLROnPlateau
    scheduler.step(avg_val_loss)

    if avg_val_loss < best_val_loss:
        best_val_loss = avg_val_loss
        epochs_no_improve = 0
        torch.save(model.state_dict(), "vit_base_multilabel_best.pth")
        print(f"‚úÖ Loss de valida√ß√£o melhorou, modelo salvo!")
    else:
        epochs_no_improve += 1
        print(f"‚ö†Ô∏è Sem melhora na valida√ß√£o por {epochs_no_improve}/{patience} √©pocas.")

    if epochs_no_improve >= patience:
        print(f"‚õî Early stopping ativado na √©poca {epoch+1}.")
        break

# ----------------- Plotagem (sem Matriz de Confus√£o, que n√£o √© ideal para multi-r√≥tulo) -----------------
df_history = pd.DataFrame(history)
df_history.to_csv('training_metrics_small_vit.csv', index=False)
print("\n‚úÖ M√©tricas de treinamento salvas.")

plt.figure(figsize=(20, 5))
plt.subplot(1, 3, 1); plt.plot(history['epoch'], history['train_loss'], label='Loss Treino'); plt.plot(history['epoch'], history['val_loss'], label='Loss Valida√ß√£o'); plt.title('Curvas de Loss'); plt.xlabel('√âpoca'); plt.legend(); plt.grid(True)
plt.subplot(1, 3, 2); plt.plot(history['epoch'], history['val_acc'], label='Acur√°cia', color='green'); plt.title('Acur√°cia Valida√ß√£o'); plt.xlabel('√âpoca'); plt.legend(); plt.grid(True)
plt.subplot(1, 3, 3); plt.plot(history['epoch'], history['val_precision'], label='Precis√£o'); plt.plot(history['epoch'], history['val_recall'], label='Recall'); plt.plot(history['epoch'], history['val_f1'], label='F1-Score'); plt.title('M√©tricas Valida√ß√£o'); plt.xlabel('√âpoca'); plt.legend(); plt.grid(True)
plt.tight_layout()
plt.savefig('training_curves_small_vit.png')
print("‚úÖ Gr√°ficos salvos.")
print("\nüéØ Pipeline de treinamento conclu√≠do.")
