import pandas as pd
import os
import json
from PIL import Image
from torch.utils.data import Dataset, DataLoader
import torch
import torch.nn as nn
import torch.optim as optim
from torchvision import transforms
import timm
from tqdm import tqdm
import matplotlib.pyplot as plt
from torch.utils.data import WeightedRandomSampler
import torchmetrics
from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay

# LÃª o arquivo CSV e obtÃ©m os nomes das classes
df = pd.read_csv('/lapix/train/_classes.csv')
class_names = sorted(df['label'].unique().tolist())
print(f"Nomes das classes encontrados: {class_names}")

# ----------------- Dataset -----------------
class LeukocyteDataset(Dataset):
    def __init__(self, csv_file, root_dir, transform=None):
        self.annotations = pd.read_csv(csv_file)
        self.root_dir = root_dir
        self.transform = transform
        self.label_names = sorted(self.annotations['label'].unique())
        self.label_to_idx = {label: idx for idx, label in enumerate(self.label_names)}

    def __len__(self):
        return len(self.annotations)

    def __getitem__(self, idx):
        img_name = os.path.join(self.root_dir, self.annotations.iloc[idx, 0])
        image = Image.open(img_name).convert('RGB')
        label_name = self.annotations.iloc[idx, 1]
        label = self.label_to_idx[label_name]

        if self.transform:
            image = self.transform(image)

        return image, label

# ----------------- HiperparÃ¢metros -----------------
BATCH_SIZE = 16
NUM_EPOCHS = 50
LR = 1e-5
patience = 7 # <-- SUGESTÃƒO: Aumentar a paciÃªncia, pois a regularizaÃ§Ã£o pode levar a uma convergÃªncia mais lenta

# ----------------- DataLoaders -----------------
train_transform = transforms.Compose([
    transforms.Resize((384, 384)),
    transforms.RandomHorizontalFlip(p=0.5),
    transforms.RandomVerticalFlip(p=0.5),
    transforms.RandomRotation(degrees=45),
    transforms.ColorJitter(brightness=0.3, contrast=0.3, saturation=0.3, hue=0.2), # <-- SUGESTÃƒO: Data Augmentation um pouco mais forte
    transforms.ToTensor(),
    transforms.Normalize([0.5]*3, [0.5]*3)
])

val_transform = transforms.Compose([
    transforms.Resize((384, 384)),
    transforms.ToTensor(),
    transforms.Normalize([0.5]*3, [0.5]*3)
])

# SEU CÃ“DIGO MODIFICADO
NOVO_CAMINHO_IMAGENS_TREINO = '/lapix/HistAuGAN/dataset/images'
train_dataset = LeukocyteDataset('/lapix/_classes.csv', NOVO_CAMINHO_IMAGENS_TREINO, transform=train_transform)
val_dataset = LeukocyteDataset('/lapix/valid/_classes.csv', 'valid', transform=val_transform)

# ----------------- Amostragem Ponderada (Weighted Sampler) -----------------
label_counts = train_dataset.annotations['label'].value_counts()
class_weights = 1.0 / label_counts
sample_weights = [class_weights[label] for label in train_dataset.annotations['label']]
sample_weights_tensor = torch.DoubleTensor(sample_weights)
sampler = WeightedRandomSampler(weights=sample_weights_tensor, num_samples=len(sample_weights_tensor), replacement=True)

train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, sampler=sampler, num_workers=4)
val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=4)

# ----------------- Dispositivo (Device) -----------------
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
print(f"Usando dispositivo: {device}")

# ----------------- Modelo -----------------
# 1. MUDANÃ‡A: Trocando para um modelo menor e adicionando mais dropout
model = timm.create_model(
    'vit_small_patch16_384', # <-- MUDANÃ‡A AQUI
    pretrained=True,
    num_classes=len(train_dataset.label_names),
    drop_rate=0.3  # <-- MUDANÃ‡A AQUI: Adiciona mais regularizaÃ§Ã£o de dropout
)
model.to(device)

criterion = nn.CrossEntropyLoss()

# 2. MUDANÃ‡A: Usando o otimizador AdamW com weight_decay
optimizer = optim.AdamW(model.parameters(), lr=LR, weight_decay=1e-2) # <-- MUDANÃ‡A AQUI

scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=15, gamma=0.1)

# --- O restante do seu cÃ³digo de treinamento, salvamento e plotagem permanece o mesmo ---
# (O cÃ³digo foi omitido por brevidade, mas ele continua igual ao que vocÃª jÃ¡ tinha)
with open('label_names.json', 'w') as f:
    json.dump(train_dataset.label_names, f)
print("âœ… Nomes dos rÃ³tulos salvos para consistÃªncia em testes futuros.")

history = {
    'epoch': [], 'train_loss': [], 'train_acc': [], 'val_loss': [], 'val_acc': [],
    'val_precision': [], 'val_recall': [], 'val_f1': []
}
num_classes = len(train_dataset.label_names)
val_precision_metric = torchmetrics.classification.Precision(task="multiclass", num_classes=num_classes, average='macro').to(device)
val_recall_metric = torchmetrics.classification.Recall(task="multiclass", num_classes=num_classes, average='macro').to(device)
val_f1_metric = torchmetrics.classification.F1Score(task="multiclass", num_classes=num_classes, average='macro').to(device)
best_val_loss = float('inf')
epochs_no_improve = 0
all_preds_final = []
all_labels_final = []

for epoch in range(NUM_EPOCHS):
    model.train()
    train_loss, correct, total = 0, 0, 0
    for images, labels in tqdm(train_loader, desc=f"Ã‰poca {epoch+1}/{NUM_EPOCHS} [Treino]"):
        images, labels = images.to(device), labels.to(device)
        optimizer.zero_grad()
        outputs = model(images)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()
        train_loss += loss.item() * images.size(0)
        _, predicted = outputs.max(1)
        correct += predicted.eq(labels).sum().item()
        total += labels.size(0)
    avg_train_loss = train_loss / total
    train_acc = correct / total

    model.eval()
    val_loss, correct, total = 0, 0, 0
    all_preds_epoch, all_labels_epoch = [], []
    with torch.no_grad():
        for images, labels in tqdm(val_loader, desc=f"Ã‰poca {epoch+1}/{NUM_EPOCHS} [Val]"):
            images, labels = images.to(device), labels.to(device)
            outputs = model(images)
            loss = criterion(outputs, labels)
            val_loss += loss.item() * images.size(0)
            _, predicted = outputs.max(1)
            correct += predicted.eq(labels).sum().item()
            total += labels.size(0)
            val_precision_metric.update(predicted, labels)
            val_recall_metric.update(predicted, labels)
            val_f1_metric.update(predicted, labels)
            all_preds_epoch.extend(predicted.cpu().numpy())
            all_labels_epoch.extend(labels.cpu().numpy())
    avg_val_loss = val_loss / total
    val_acc = correct / total
    val_precision = val_precision_metric.compute()
    val_recall = val_recall_metric.compute()
    val_f1 = val_f1_metric.compute()
    val_precision_metric.reset()
    val_recall_metric.reset()
    val_f1_metric.reset()

    print(f"\nâœ… Ã‰poca [{epoch+1}/{NUM_EPOCHS}] Treino Loss: {avg_train_loss:.4f} | Treino Acc: {train_acc:.4f}\n"
          f"Val Loss: {avg_val_loss:.4f}  | Val Acc: {val_acc:.4f} | Val Precision: {val_precision:.4f} | Val Recall: {val_recall:.4f} | Val F1: {val_f1:.4f}\n")
    
    history['epoch'].append(epoch + 1); history['train_loss'].append(avg_train_loss); history['train_acc'].append(train_acc)
    history['val_loss'].append(avg_val_loss); history['val_acc'].append(val_acc); history['val_precision'].append(val_precision.item())
    history['val_recall'].append(val_recall.item()); history['val_f1'].append(val_f1.item())
    
    scheduler.step()

    if avg_val_loss < best_val_loss:
        best_val_loss = avg_val_loss
        epochs_no_improve = 0
        torch.save(model.state_dict(), "vit_best_model.pth")
        all_preds_final, all_labels_final = all_preds_epoch, all_labels_epoch
        print(f"âœ… Loss de validaÃ§Ã£o melhorou, modelo salvo como vit_best_model.pth")
    else:
        epochs_no_improve += 1
        print(f"âš ï¸ Sem melhora por {epochs_no_improve}/{patience} Ã©pocas.")
    if epochs_no_improve >= patience:
        print(f"â›” Early stopping ativado na Ã©poca {epoch+1}. Melhor Val Loss: {best_val_loss:.4f}")
        break
    
    torch.save(model.state_dict(), f"vit_epoch_{epoch+1}.pth")
    torch.cuda.empty_cache()

df_history = pd.DataFrame(history)
df_history.to_csv('training_metrics.csv', index=False)
print("âœ… MÃ©tricas de treinamento salvas em training_metrics.csv")

# ... (cÃ³digo de plotagem e matriz de confusÃ£o) ...
# ----------------- Plotar Curvas de MÃ©tricas ----------------- # <-- Modificado
plt.figure(figsize=(20, 6))

# Loss
plt.subplot(1, 3, 1)
plt.plot(history['epoch'], history['train_loss'], label='Train Loss')
plt.plot(history['epoch'], history['val_loss'], label='Validation Loss')
plt.xlabel('Ã‰poca'); plt.ylabel('Loss'); plt.title('Loss ao Longo das Ã‰pocas'); plt.legend(); plt.grid(True)

# AcurÃ¡cia
plt.subplot(1, 3, 2)
plt.plot(history['epoch'], history['train_acc'], label='Train Accuracy')
plt.plot(history['epoch'], history['val_acc'], label='Validation Accuracy')
plt.xlabel('Ã‰poca'); plt.ylabel('AcurÃ¡cia'); plt.title('AcurÃ¡cia ao Longo das Ã‰pocas'); plt.legend(); plt.grid(True)

# Precision, Recall, F1
plt.subplot(1, 3, 3)
plt.plot(history['epoch'], history['val_precision'], label='Validation Precision')
plt.plot(history['epoch'], history['val_recall'], label='Validation Recall')
plt.plot(history['epoch'], history['val_f1'], label='Validation F1-Score')
plt.xlabel('Ã‰poca'); plt.ylabel('Score'); plt.title('Precision, Recall & F1-Score'); plt.legend(); plt.grid(True)

plt.tight_layout()
plt.savefig('training_curves_all_metrics.png', dpi=300)
plt.show()
print("âœ… Curvas de mÃ©tricas salvas em training_curves_all_metrics.png")

print("\nðŸŽ¯ Pipeline de treinamento concluÃ­do com sucesso.")
